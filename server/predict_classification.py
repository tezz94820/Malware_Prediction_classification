import os
import numpy as np
import pandas as pd
import joblib
import sys
import glob
import json

# load totals
import json
file_path = 'totals.json'
with open(file_path, 'r') as file:
    json_string = file.read()
loaded_dict = json.loads(json_string)
# print("Loaded dictionary:", loaded_dict)

# Normalize function
def normalize(df):
    result1 = df.copy()
    for feature_name in df.columns:
        if (str(feature_name) != str('ID') and str(feature_name)!=str('Class')):
            max_value = float(loaded_dict[feature_name]['max'])
            min_value = float(loaded_dict[feature_name]['min'])
            result1[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)
    return result1


def txt_to_hex_formatted(input_file, output_file):
    # Read the content of the input text file as bytes
    with open(input_file, 'rb') as file:
        content = file.read()
    
    if content[:1].islower():
        # Convert the bytes to a hexadecimal string
        hex_string = content.hex().upper()
        
        # Format the hexadecimal string into the desired format
        formatted_lines = []
        bytes_per_line = 16
        
        for i in range(0, len(hex_string), bytes_per_line * 2):
            line = hex_string[i:i + bytes_per_line * 2]
            formatted_line = ' '.join(line[j:j + 2] for j in range(0, len(line), 2))
            formatted_lines.append(formatted_line)
        
        # Write the formatted lines to the output file
        parts = output_file.split('/')
        new_output_file = parts[0] + '/new_' + parts[1]
        with open(new_output_file, 'w') as file:
            file.write('\n'.join(formatted_lines))
    else:
        with open(output_file, 'wb') as file:
            file.write(content)
        


def delete_all_files(folder_path):
    files = glob.glob(os.path.join(folder_path, '*'))
    for f in files:
        if os.path.isfile(f):
            os.remove(f)


# load the model
loaded_model = joblib.load('xgboost_model.pkl')

malwares = {
    '0':{'family_name':'Ramnit','Type':'Worm'},
    '1':{'family_name':'Lollipop','Type':'Adware'},
    '2':{'family_name':'Kelihos_ver3','Type':'Backdoor'},
    '3':{'family_name':'Vundo','Type':'Trojan'},
    '4':{'family_name':'Simda','Type':'Backdoor'},
    '5':{'family_name':'Tracur','Type':'TrojanDownloader'},
    '6':{'family_name':'Kelihos_ver1','Type':'Backdoor'},
    '7':{'family_name':'Obfuscator.ACY','Type':'Any Kind of obfuscated malware'},
    '8':{'family_name':'Gatak','Type':'Backdoor'},
}

def get_predictions(folder_name,file):
    # read the file
    fileName = file.split('.')[0]
    # print(fileName)
    if(fileName.startswith('new_')):
        dict_to_print = { 'fileName':fileName.split('_')[1], 'malwareFamily': 'Not a Malware', 'malwareType': 'Not a Malware' }
        print(json.dumps(dict_to_print))
        return
    # get the size of file as feature
    statinfo=os.stat(folder_name + '/' +file)
    sizebytes = statinfo.st_size/(1024.0*1024.0)
    data_size_byte=pd.DataFrame({'ID':[fileName],'size':[sizebytes]})
    # getting the unigram features
    filenames2=[]
    feature_matrix = np.zeros((1,257),dtype=int)
    k=0
    byte_feature_file=open('result1.csv','w+')
    byte_feature_file.write("ID,0,1,2,3,4,5,6,7,8,9,0a,0b,0c,0d,0e,0f,10,11,12,13,14,15,16,17,18,19,1a,1b,1c,1d,1e,1f,20,21,22,23,24,25,26,27,28,29,2a,2b,2c,2d,2e,2f,30,31,32,33,34,35,36,37,38,39,3a,3b,3c,3d,3e,3f,40,41,42,43,44,45,46,47,48,49,4a,4b,4c,4d,4e,4f,50,51,52,53,54,55,56,57,58,59,5a,5b,5c,5d,5e,5f,60,61,62,63,64,65,66,67,68,69,6a,6b,6c,6d,6e,6f,70,71,72,73,74,75,76,77,78,79,7a,7b,7c,7d,7e,7f,80,81,82,83,84,85,86,87,88,89,8a,8b,8c,8d,8e,8f,90,91,92,93,94,95,96,97,98,99,9a,9b,9c,9d,9e,9f,a0,a1,a2,a3,a4,a5,a6,a7,a8,a9,aa,ab,ac,ad,ae,af,b0,b1,b2,b3,b4,b5,b6,b7,b8,b9,ba,bb,bc,bd,be,bf,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9,ca,cb,cc,cd,ce,cf,d0,d1,d2,d3,d4,d5,d6,d7,d8,d9,da,db,dc,dd,de,df,e0,e1,e2,e3,e4,e5,e6,e7,e8,e9,ea,eb,ec,ed,ee,ef,f0,f1,f2,f3,f4,f5,f6,f7,f8,f9,fa,fb,fc,fd,fe,ff,??")
    byte_feature_file.write("\n")
    filenames2.append(file)
    byte_feature_file.write(file+",")
    if(file.endswith("txt")):
        with open(folder_name + '/' +file,"r") as byte_flie:
            for lines in byte_flie:
                line=lines.rstrip().split(" ")
                for hex_code in line:
                    if hex_code=='??':
                        feature_matrix[k][256]+=1
                    else:
                        feature_matrix[k][int(hex_code,16)]+=1
        byte_flie.close()
    for i, row in enumerate(feature_matrix[k]):
        if i!=len(feature_matrix[k])-1:
            byte_feature_file.write(str(row)+",")
        else:
            byte_feature_file.write(str(row))
    byte_feature_file.write("\n")
    k += 1
    byte_feature_file.close()
    # reading the result1.csv
    byte_features=pd.read_csv("result1.csv")
    byte_features['ID']  = byte_features['ID'].str.split('.').str[0]
    # merging with byte features
    byte_features_with_size = byte_features.merge(data_size_byte, on='ID')
    # normalizing the features
    result = normalize(byte_features_with_size)
    X_train = result.drop(columns=['ID'])
    # print('fileName = ',fileName)
    #prediction result
    prediction = loaded_model.predict(X_train)[0]
    # print('predicted =',prediction)
    # # real result
    # try:
    #     class_value = df.loc[df['Id'] == fileName, 'Class'].values[0]
    #     print("real",class_value)
    # except IndexError:
    #     print("ID {} not found in the dataset.".format(fileName))
    malware_predicted = malwares[str(prediction)]
    # print('Family Name = ',malware_predicted['family_name'])
    # print('Malware Type = ',malware_predicted['Type'])
    dict_to_print = { 'fileName':fileName, 'malwareFamily': malware_predicted['family_name'], 'malwareType':malware_predicted['Type'] }
    print(json.dumps(dict_to_print))

folder_name = sys.argv[1] # folder name where the txt files giving for prediction
print('Folder Name = ',folder_name)
hexadecimal_folder = 'recent_classification_bytecode'  
delete_all_files(hexadecimal_folder) # deleting the files in fodler  which will contain files in hexadcimal foramt 
sys.stdout = open("result_classification.txt", "w") # storing the result here

files = os.listdir(folder_name)
for file in files:
    if(file.endswith("txt")):
        txt_to_hex_formatted(folder_name + '/' +file, hexadecimal_folder+'/'+file)

files = os.listdir(hexadecimal_folder)
for file in files:
        get_predictions(hexadecimal_folder,file)

sys.stdout = sys.__stdout__

# print(sys.argv)